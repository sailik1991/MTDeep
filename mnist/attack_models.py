# Project      : MTDeep-- Boosting the Security of Deep Neural Nets Against Adversarial Attacks
#                with Moving Target Defense
# laboratory   : Yochan
# Last update  : 19th May, 2019
# username     : sailiks1991
# name         : Sailik Sengupta
# description  : Trains constituent models in an ensemble.
#                Uses a set of white-box attacks against each of them and reports the accuracies.

import sys
from mnist_helper import *

import keras
import tensorflow as tf
import cleverhans

import constituent_models.mnist_cnn1 as mnist_cnn1
import constituent_models.mnist_hierarchical_rnn as mnist_hierarchical_rnn
import constituent_models.mnist_irnn as mnist_irnn
import constituent_models.mnist_mlp as mnist_mlp

SMALL_BATCH_SIZE = 11

# --- DeepFool ---
def get_DF_cg(sess, wrap, x):
    attack = cleverhans.attacks.DeepFool(wrap, back='tf', sess=sess)
    # Consider only three class when searching for a successful attack perturbation
    attack_params = {'nb_candidate': 3}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

# --- Fast Gradient Method ----
def get_FGM_cg(sess, wrap, x):
    attack = cleverhans.attacks.FastGradientMethod(wrap, sess=sess)
    attack_params = {'eps': 0.3}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

# --- Projected Gradient Descent ---
def get_PGD_cg(sess, wrap, x, y):
    attack = cleverhans.attacks.ProjectedGradientDescent(wrap, sess=sess)
    attack_params = {'eps': 0.3, 'eps_iter': 0.05, 'y': y}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

def main(sess, model_type=''):
    # ----- Get train and test data -----
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

    # ----- Get models for the ensemble -----
    models = {}
    for model_name in ['mlp', 'cnn', 'hrnn']:
        try:
            print('[DEBUG] Loading model.')
            models[model_name] = load_model('{}{}'.format(model_type, model_name))
        except:
            if model_type == 'AT_' or model_type == 'EAT_':
                print('[ERROR] Adversarially Trained models not found! Train and save strengthened models first. Then, run this.')
                exit(1)
            print('[DEBUG] Loading failed. Trying to train the constituent model.')
            models = get_trained_models(x_train, y_train, x_test, y_test)
    
    # ----- Make model ready for seamless interfacing with cleverhans attacks -----
    print('[DEBUG] Attacking the constituent models.')
    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
    y = tf.placeholder(tf.float32, shape=(None, 10))

    wraps = {}
    adv_xs = {}
    for model_name in models.keys():
        wraps[model_name] = cleverhans.utils_keras.KerasModelWrapper(models[model_name])
        '''
        WARNING: Do not try to find all the adv examples generated by different attack methods at a single time
                 unless you have a lot of memory to support the multiple computational graphs (one per attack).
                 Comment out one by one and obtain metrices separately if you don't have enough resources.
        '''
        adv_xs['${}_{}$'.format('FGM', model_name[0])] = get_FGM_cg(sess, wraps[model_name], x)
        #adv_xs['${}_{}$'.format('DF', model_name[0])] = get_DF_cg(sess, wraps[model_name], x)
        #adv_xs['${}_{}$'.format('PGD', model_name[0])] = get_PGD_cg(sess, wraps[model_name], x, y)

    # --- Print out an accuracy table ---
    keras.backend.set_learning_phase(0)
    eval_params = {'batch_size': 128}
    
    table_header = 'model '
    accuracy_test = ''
    accuracy_attack = ''

    # Make keras data ready for evaluations using cleverhans tensorflow modules.
    x_train, y_train, x_test, y_test = process_data(x_train, y_train, x_test, y_test)
    for model_name in models.keys():

        accuracy_attack += '{} '.format(model_name)
        accuracy = cleverhans.utils_tf.model_eval(sess, x, y, models[model_name](x), x_test, y_test, args=eval_params)
        accuracy_test += '{}\n'.format(accuracy * 100)

        # For each model, apply all attacks.
        for attack_name in adv_xs.keys():
            print('[DEBUG] Attacking {} using {}.'.format(model_name, attack_name))
            
            # This code branch is only entered once-- when computing accuracies for the first model.
            # Needed for generating the table header.
            if attack_name not in table_header:
                table_header += '{} '.format(attack_name)
            
            accuracy = cleverhans.utils_tf.model_eval(sess, x, y, models[model_name](adv_xs[attack_name]), x_test, y_test, args=eval_params)
            accuracy_attack += '{} '.format(accuracy * 100)
        
        # Move on to the next model.
        accuracy_attack += '\n'
    
    print(table_header)
    print(accuracy_attack)
    print(accuracy_test)

if __name__ == '__main__':
    sess = tf.Session()
    keras.backend.set_session(sess)
    if len(sys.argv) == 2:
        if sys.argv[1] == '--at':
            print('[INFO] Attacking adversarially trained constituent models.')
            main(sess, model_type = 'AT_')
        elif sys.argv[1] == '--eat':
            print('[INFO] Attakcing ensemble adversarially trained constituent models.')
            main(sess, model_type = 'EAT_')
        else:
            print('[INFO] Attacking vanilla models.')
            main(sess)
    else:
        main(sess)
