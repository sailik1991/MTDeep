# Project      : MTDeep-- Boosting the Security of Deep Neural Nets Against Adversarial Attacks
#                with Moving Target Defense
# laboratory   : Yochan
# Last update  : 19th May, 2019
# username     : sailiks1991
# name         : Sailik Sengupta
# description  : Trains constituent models in an ensemble.
#                Uses a set of white-box attacks against each of them and reports the accuracies.

import sys
from mnist_helper import *

import keras
import tensorflow as tf
import cleverhans

import constituent_models.mnist_cnn1 as mnist_cnn1
import constituent_models.mnist_hierarchical_rnn as mnist_hierarchical_rnn
import constituent_models.mnist_irnn as mnist_irnn
import constituent_models.mnist_mlp as mnist_mlp

# --- Projected Gradient Descent ---
def get_PGD_cg(sess, wrap, x, y):
    attack = cleverhans.attacks.ProjectedGradientDescent(wrap, sess=sess)
    # Consider only three class when searching for a successful attack perturbation
    attack_params = {'eps': 0.3, 'eps_iter': 0.05, 'nb_iter': 10, 'y': y}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

# --- DeepFool ---
def get_DF_cg(sess, wrap, x):
    attack = cleverhans.attacks.DeepFool(wrap, back='tf', sess=sess)
    # Consider only three class when searching for a successful attack perturbation
    attack_params = {'nb_candidate': 3}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

# --- Fast Gradient Method ----
def get_FGM_cg(sess, wrap, x):
    attack = cleverhans.attacks.FastGradientMethod(wrap, sess=sess)
    attack_params = {'eps': 0.3}
    adv_x = attack.generate(x, **attack_params)
    adv_x = tf.stop_gradient(adv_x)
    return adv_x

def main(sess):
    # ----- Get train and test data -----
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train, y_train, x_test, y_test = process_data(x_train, y_train, x_test, y_test)

    # ----- Get models for the ensemble -----
    models = {}
    for model_name in ['mlp', 'cnn', 'hrnn']:
        try:
            print('[DEBUG] Loading model.')
            models[model_name] = load_model(model_name)
        except:
            print('[DEBUG] Loading failed. Trying to train the constituent model.')
            print('[ERROR] Training failed. Configuration problems to be fixed.')
            exit(1)
            models['mlp'] = mnist_mlp.get_vanilla_model()
            models['cnn'] = mnist_cnn1.get_vanilla_model()
            # The code for hierarchical rnn needs the data to be provided as argument
            models['hrnn'] = mnist_hierarchical_rnn.get_model(
                    x_train,
                    y_train,
                    x_test,
                    y_test,
                    getVanilla=True
            )

    # ----- Make model ready for seamless interfacing with cleverhans attacks -----
    print('[DEBUG] Attacking the constituent models.')
    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
    y = tf.placeholder(tf.float32, shape=(None, 10))

    wraps = {}
    adv_xs = {}
    for model_name in models.keys():
        wraps[model_name] = cleverhans.utils_keras.KerasModelWrapper(models[model_name])
        '''
        WARNING: Do not try to find all the adv examples generated by different attack methods at a single time
                 unless you have a lot of memory to support the multiple computational graphs (one per attack).
                 Comment out one by one and obtain metrices separately if you don't have enough resources.
        '''
        adv_xs['${}_{}$'.format('FGM', model_name[0])] = get_FGM_cg(sess, wraps[model_name], x)
        # adv_xs['${}_{}$'.format('PGD', model_name[0])] = get_PGD_cg(sess, wraps[model_name], x, y)
        # adv_xs['${}_{}$'.format('DF', model_name[0])] = get_DF_cg(sess, wraps[model_name], x)

    # --- Print out an accuracy table ---
    keras.backend.set_learning_phase(0)
    eval_params = {'batch_size': 128}
    
    table_header = 'model '
    accuracy_test = ''
    accuracy_attack = ''
 
    for model_name in models.keys():

        accuracy_attack += '{} '.format(model_name)
        accuracy = cleverhans.utils_tf.model_eval(sess, x, y, models[model_name](x), x_test, y_test, args=eval_params)
        accuracy_test += '{}\n'.format(accuracy * 100)

        # For each model, apply all attacks.
        for attack_name in adv_xs.keys():

            # This code branch is only entered once-- when computing accuracies for the first model.
            # Need for generating the table header.
            if attack_name not in table_header:
                table_header += '{} '.format(attack_name)

            accuracy = cleverhans.utils_tf.model_eval(sess, x, y, models[model_name](adv_xs[attack_name]), x_test, y_test, args=eval_params)
            accuracy_attack += '{} '.format(accuracy * 100)
        
        # Move on to the next model.
        accuracy_attack += '\n'
    
    print(table_header)
    print(accuracy_attack)
    print(accuracy_test)

if __name__ == '__main__':
    sess = tf.Session()
    keras.backend.set_session(sess)
    
    main(sess)
